# Unveiling Entropy: Maclaurin Series - A Novel Paradigm for Random Forest Algorithm  

## Overview  
This project implements Random Forest with entropy computation modified using Maclaurin series expansion. The approach enhances model adaptability, providing a more flexible entropy formulation.

## Key Insights  
- **Maclaurin Series in Entropy**: Instead of conventional entropy calculations, we approximate entropy using Maclaurin series to achieve better classification accuracy.  
- **Comparison Analysis**: In evaluating entropy values, -0.107 is closer to zero compared to 2.237, indicating less entropy and more predictability in the dataset. Hence, -0.107 is considered the better entropy value in this case.  

## Features  
- Implementation of Random Forest using Maclaurin series-based entropy.  
- Performance comparison with traditional entropy-based splitting criteria.  
- Analysis of entropy values for improved model efficiency.  

