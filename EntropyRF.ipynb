{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LOC_BLANK  BRANCH_COUNT  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
      "0        447           826                    12           157   \n",
      "1         37            29                     8            42   \n",
      "2         11           405                     0            17   \n",
      "3        106           240                     7           344   \n",
      "4        101           464                    11            75   \n",
      "\n",
      "   CYCLOMATIC_COMPLEXITY  DESIGN_COMPLEXITY  ESSENTIAL_COMPLEXITY  \\\n",
      "0                    470                385                   113   \n",
      "1                     19                 19                     6   \n",
      "2                    404                  2                     1   \n",
      "3                    127                105                    33   \n",
      "4                    263                256                   140   \n",
      "\n",
      "   LOC_EXECUTABLE  HALSTEAD_CONTENT  HALSTEAD_DIFFICULTY  ...  \\\n",
      "0            2824            210.28               384.45  ...   \n",
      "1             133            108.14                46.32  ...   \n",
      "2             814            101.20               206.01  ...   \n",
      "3             952            218.17               215.17  ...   \n",
      "4            1339            106.50               337.36  ...   \n",
      "\n",
      "   HALSTEAD_LENGTH  HALSTEAD_LEVEL  HALSTEAD_PROG_TIME  HALSTEAD_VOLUME  \\\n",
      "0             8441            0.00          1726654.57         80843.08   \n",
      "1              685            0.02            12891.31          5009.32   \n",
      "2             2033            0.00           238607.05         20848.47   \n",
      "3             5669            0.00           561159.25         46943.69   \n",
      "4             4308            0.00           673377.60         35928.07   \n",
      "\n",
      "   NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
      "0          3021           5420                  609                   155   \n",
      "1           295            390                  121                    38   \n",
      "2           813           1220                  811                   411   \n",
      "3          2301           3368                  262                    49   \n",
      "4          1556           2752                  226                    98   \n",
      "\n",
      "   LOC_TOTAL  label  \n",
      "0       3442      Y  \n",
      "1        222      Y  \n",
      "2        844      Y  \n",
      "3       1411      Y  \n",
      "4       1532      Y  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('balanced_data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LOC_BLANK','BRANCH_COUNT','LOC_CODE_AND_COMMENT','LOC_COMMENTS','CYCLOMATIC_COMPLEXITY','DESIGN_COMPLEXITY',\n",
    "            'ESSENTIAL_COMPLEXITY','LOC_EXECUTABLE','HALSTEAD_CONTENT','HALSTEAD_DIFFICULTY','HALSTEAD_EFFORT','HALSTEAD_ERROR_EST',\n",
    "            'HALSTEAD_LENGTH','HALSTEAD_LEVEL','HALSTEAD_PROG_TIME','HALSTEAD_VOLUME','NUM_OPERANDS','NUM_OPERATORS','NUM_UNIQUE_OPERANDS',\n",
    "            'NUM_UNIQUE_OPERATORS','LOC_TOTAL']\n",
    "nb_train = int(np.floor(0.9 * len(df)))\n",
    "df = df.sample(frac=1, random_state=217)\n",
    "X_train = df[features][:nb_train]\n",
    "y_train = df['label'][:nb_train].values\n",
    "X_test = df[features][nb_train:]\n",
    "y_test = df['label'][nb_train:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    elif p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
    "\n",
    "def information_gain(left_child, right_child):\n",
    "    parent = left_child + right_child\n",
    "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
    "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
    "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
    "    IG_p = entropy(p_parent)\n",
    "    IG_l = entropy(p_left)\n",
    "    IG_r = entropy(p_right)\n",
    "    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bootstrap(X_train, y_train):\n",
    "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
    "    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "    X_oob = X_train.iloc[oob_indices].values\n",
    "    y_oob = y_train[oob_indices]\n",
    "    return X_bootstrap, y_bootstrap, X_oob, y_oob\n",
    "\n",
    "def oob_score(tree, X_test, y_test):\n",
    "    mis_label = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = predict_tree(tree, X_test[i])\n",
    "        if pred != y_test[i]:\n",
    "            mis_label += 1\n",
    "    return mis_label / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split_point(X_bootstrap, y_bootstrap, max_features):\n",
    "    feature_ls = list()\n",
    "    num_features = len(X_bootstrap[0])\n",
    "\n",
    "    while len(feature_ls) <= max_features:\n",
    "        feature_idx = random.sample(range(num_features), 1)\n",
    "        if feature_idx not in feature_ls:\n",
    "            feature_ls.extend(feature_idx)\n",
    "\n",
    "    best_info_gain = -999\n",
    "    node = None\n",
    "    for feature_idx in feature_ls:\n",
    "        for split_point in X_bootstrap[:,feature_idx]:\n",
    "            left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "            right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "\n",
    "        # split children for continuous variables\n",
    "        if type(split_point) in [int, float]:\n",
    "            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                if value <= split_point:\n",
    "                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                else:\n",
    "                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "        # split children for categoric variables\n",
    "        else:\n",
    "            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                if value == split_point:\n",
    "                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                else:\n",
    "                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "\n",
    "        split_info_gain = information_gain(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
    "        if split_info_gain > best_info_gain:\n",
    "            best_info_gain = split_info_gain\n",
    "            left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
    "            right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
    "            node = {'information_gain': split_info_gain,\n",
    "                    'left_child': left_child,\n",
    "                    'right_child': right_child,\n",
    "                    'split_point': split_point,\n",
    "                    'feature_idx': feature_idx}\n",
    "\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_node(node):\n",
    "    y_bootstrap = node['y_bootstrap']\n",
    "    pred = max(y_bootstrap, key = y_bootstrap.count)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
    "    left_child = node['left_child']\n",
    "    right_child = node['right_child']\n",
    "\n",
    "    del(node['left_child'])\n",
    "    del(node['right_child'])\n",
    "\n",
    "    if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
    "        empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
    "        node['left_split'] = terminal_node(empty_child)\n",
    "        node['right_split'] = terminal_node(empty_child)\n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        node['left_split'] = terminal_node(left_child)\n",
    "        node['right_split'] = terminal_node(right_child)\n",
    "        return node\n",
    "\n",
    "    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
    "    else:\n",
    "        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
    "        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
    "    else:\n",
    "        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
    "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
    "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "    return root_node\n",
    "\n",
    "def random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "    tree_ls = list()\n",
    "    oob_ls = list()\n",
    "    for i in range(n_estimators):\n",
    "        X_bootstrap, y_bootstrap, X_oob, y_oob = draw_bootstrap(X_train, y_train)\n",
    "        tree = build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "        tree_ls.append(tree)\n",
    "        oob_error = oob_score(tree, X_oob, y_oob)\n",
    "        oob_ls.append(oob_error)\n",
    "    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
    "    return tree_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(tree, X_test):\n",
    "    feature_idx = tree['feature_idx']\n",
    "\n",
    "    if X_test[feature_idx] <= tree['split_point']:\n",
    "        if type(tree['left_split']) == dict:\n",
    "            return predict_tree(tree['left_split'], X_test)\n",
    "        else:\n",
    "            value = tree['left_split']\n",
    "            return value\n",
    "    else:\n",
    "        if type(tree['right_split']) == dict:\n",
    "            return predict_tree(tree['right_split'], X_test)\n",
    "        else:\n",
    "            return tree['right_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(tree_ls, X_test):\n",
    "    pred_ls = list()\n",
    "    for i in range(len(X_test)):\n",
    "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "        pred_ls.append(final_pred)\n",
    "    return np.array(pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "max_features = 10\n",
    "max_depth = 10\n",
    "min_samples_split = 3\n",
    "\n",
    "model = random_forest(X_train, y_train, n_estimators=100, max_features=10, max_depth=10, min_samples_split=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_rf(model, X_test)\n",
    "acc = sum(preds == y_test) / len(y_test)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Entropy Value: \",entropy)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Testing accuracy:\", accuracy)\n",
    "\n",
    "# Construct confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, preds, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, preds, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, preds, average='weighted')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the metrics and their values\n",
    "metrics = ['Testing Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "values = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of Classification Metrics')\n",
    "plt.ylim(0, 1)  # Limit y-axis to [0, 1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
